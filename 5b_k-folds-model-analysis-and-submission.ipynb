{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"# This notebook is for testing predictions and submitting models/results for the competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing EfficientNet model without internet due to competition requisites\n\nimport os\nimport sys\n\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path\n\nimport torch\nos.listdir(\"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master\")\n\n\nfrom efficientnet_pytorch import EfficientNet\n\n\n#!pip install efficientnet_pytorch torchtoolbox\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n# Imports here\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport pandas as pd\nimport os\nimport random\nimport math\nimport skimage.io\n#from csv_loader import load_csv\n\n# Tiff visualisation imports and downloads\nimport numpy as np\nimport tifffile as tiff\n\n# For re-importing python modules\nimport importlib\nimport imagecodecs","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.set_default_tensor_type(torch.cuda.FloatTensor)","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the image manipulation functions to later use them in the dataloader function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# first version of dataloader to make predictions with available data from train_images.\n# There will be a second version of the loader that will perform image manipulations for running test/submission data\nclass load_csv(Dataset):\n    def __init__(self, csv_file, root_dir, transform=True):\n        self.annotations = pd.read_csv(csv_file)# todo remove sample for debug\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.annotations)\n        \n    \n    def __getitem__(self, index):\n        #img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image_id = self.annotations.iloc[index, 0]\n        img_path = os.path.join(self.root_dir, str(image_id) +\".png\")\n        image = torch.from_numpy(skimage.io.imread(img_path)).permute(2,0,1).float()\n        \n        #Image.MAX_IMAGE_PIXELS = None\n                \n        #image.transform = transforms.RandomResizedCrop(224)\n        \n        y_label = torch.tensor(int(self.annotations.iloc[index,:]['isup_grade']))\n        #isup_grade = int(self.annotations.iloc[index,:]['isup_grade'])\n        \n        #label = np.zeros(6).astype(np.float32)\n        #y_label = label[isup_grade] = 1.\n        #y_label = torch.tensor(y_label)\n        \n        self.transform= transforms.Compose([transforms.ToPILImage(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, y_label, image_id","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define model and validate function"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Define/load base model\nmodel = EfficientNet.from_name('efficientnet-b4')\nmodel.load_state_dict(torch.load(\"../input/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth\"))\n\n\nmodel._fc = nn.Sequential(nn.Linear(model._fc.in_features, 216),\n                          nn.ReLU(),\n                          nn.Linear(216, 36, bias=True),\n                          nn.ReLU(),\n                          nn.Linear(36, 6, bias=True),\n                          nn.LogSoftmax(dim=1))\n\n\n# Load checkpoint\ncheckpoint = torch.load(\"../input/training-model-with-k-folds/model_fold_0.pth\")\n\n# Load model parameters\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel._fc.load_state_dict(checkpoint['classifier_state_dict'])\n\n# Load other model related components\ncriterion = nn.NLLLoss()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nfold = checkpoint['fold']\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel.eval()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"EfficientNet(\n  (_conv_stem): Conv2dStaticSamePadding(\n    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n  )\n  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n  (_blocks): ModuleList(\n    (0): MBConvBlock(\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        48, 12, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        12, 48, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (1): MBConvBlock(\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        24, 6, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        6, 24, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (2): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        144, 6, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        6, 144, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (3): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        192, 8, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        8, 192, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (4): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        192, 8, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        8, 192, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (5): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        192, 8, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        8, 192, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (6): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        192, 8, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        8, 192, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (7): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        336, 14, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        14, 336, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (8): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        336, 14, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        14, 336, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (9): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        336, 14, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        14, 336, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (10): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        336, 14, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        14, 336, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (11): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (12): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (13): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (14): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (15): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (16): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (17): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        960, 40, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        40, 960, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (18): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        960, 40, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        40, 960, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (19): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        960, 40, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        40, 960, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (20): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        960, 40, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        40, 960, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (21): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        960, 40, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        40, 960, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (22): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        960, 40, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        40, 960, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (23): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (24): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (25): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (26): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (27): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (28): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (29): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (30): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n    (31): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n      )\n      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    )\n  )\n  (_conv_head): Conv2dStaticSamePadding(\n    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n    (static_padding): Identity()\n  )\n  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n  (_fc): Sequential(\n    (0): Linear(in_features=1792, out_features=216, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=216, out_features=36, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=36, out_features=6, bias=True)\n    (5): LogSoftmax()\n  )\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation function\ndef validate_data_function(model, test_loader, criterion):\n    test_loss = 0\n    accuracy = 0\n    \n    df_test = {'image_id': [],\n             'label': [],\n             'y_pred': []}\n    \n    for ii, (inputs, labels, image_id) in enumerate(test_loader):\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        output = model.forward(inputs)\n        pred_y = output.argmax(dim=1)\n        \n        \n        #ps = torch.exp(output)\n        #equality = (labels.argmax(dim=1) == output.argmax(dim=1))\n        equality = (labels == output.argmax(dim=1))\n        accuracy += equality.type(torch.FloatTensor)\n        \n        df_test['image_id'].append(image_id[0])\n        df_test['label'].append(int(labels[0]))\n        df_test['y_pred'].append(int(pred_y[0]))\n        \n    \n    accuracy = accuracy/len(test_loader)\n    accuracy.item\n    return test_loss, accuracy[0], image_id, pred_y, labels, df_test\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyzing each fold's prediction strength and assigning weights to calculate final k-folds weighted averages for future predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seeing how well each of the folds predict their own test sets\nnum_folds = 5\nsample_size = 100\n\npred_y_collection = []\nfor i in range(num_folds):\n    # Load checkpoint\n    checkpoint_name = \"../input/training-model-with-k-folds/model_fold_\" + str(i) + \".pth\"\n    checkpoint = torch.load(checkpoint_name)\n\n    # Load model parameters\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model._fc.load_state_dict(checkpoint['classifier_state_dict'])\n\n    # Load other model related components\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    fold = checkpoint['fold']\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n    \n    # Load appropriate data (can't use non-test images for testing/predicting)\n    file_path = '../input/training-model-with-k-folds/test_fold_' + str(0) + '.csv'\n    fold_test_set = pd.read_csv(file_path).copy()\n    fold_test_set = fold_test_set.sample(sample_size)\n    \n    fold_sample_name = 'sample_fold_' + str(i) + '.csv'\n    fold_test_set.to_csv(fold_sample_name, sep=\",\", index=False)\n    test_data = load_csv(csv_file=fold_sample_name, root_dir='../input/prostate-cancer-tiles-4x4x128px-downsampling-4x/train_128x4x4_res1/train_128x4x4_res1')\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n    \n    # Run predictions for each fold and hopefully get insights\n    model.eval()\n    \n    with torch.no_grad():\n        test_loss, accuracy, image_id, pred_y, labels, df_test = validate_data_function(model, test_loader, criterion)\n    pred_y_collection.append(df_test)\n    print(\"|Fold: {}  |Test Accuracy: {:.2f}%\".format(fold, accuracy))#*100/len(train_loader)))","execution_count":41,"outputs":[{"output_type":"stream","text":"|Fold: 0  |Test Accuracy: 0.55%\n|Fold: 1  |Test Accuracy: 0.58%\n|Fold: 2  |Test Accuracy: 0.52%\n|Fold: 3  |Test Accuracy: 0.59%\n|Fold: 4  |Test Accuracy: 0.49%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fold_strengths(df_test, scores=6):\n    weights = []\n    for i in range(scores):\n        df_label = df_test[df_test['label']==i]\n        equality = df_label[df_label['y_pred']==i]\n        label_accuracy = len(equality)/len(df_label)\n        weights.append(label_accuracy)\n    total_equality = df_test[df_test['label']==df_test['y_pred']]\n    total_accuracy = len(total_equality)/len(df_test)\n    return total_accuracy, weights","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_dic","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"[[0.8214285714285714,\n  0.7575757575757576,\n  0.4444444444444444,\n  0.14285714285714285,\n  0.0,\n  0.2222222222222222],\n [0.8461538461538461,\n  0.6071428571428571,\n  0.375,\n  0.23076923076923078,\n  0.08333333333333333,\n  0.9230769230769231],\n [0.5625,\n  0.8695652173913043,\n  0.14285714285714285,\n  0.4166666666666667,\n  0.0,\n  0.5384615384615384],\n [0.8709677419354839,\n  0.41935483870967744,\n  0.4,\n  0.25,\n  0.14285714285714285,\n  0.9230769230769231],\n [0.8064516129032258,\n  0.8181818181818182,\n  0.14285714285714285,\n  0.08333333333333333,\n  0.08333333333333333,\n  0.2222222222222222]]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_dic = []\nfor i in range(num_folds):\n    print(\"Fold {}\".format(i))\n    total_accuracy, weights = fold_strengths(pd.DataFrame(pred_y_collection[i]), scores=6)\n    weights_dic.append(weights)\n    print(weights)\npd.DataFrame(weights_dic).to_csv('weights_dic.csv', sep=\",\", index=False)","execution_count":54,"outputs":[{"output_type":"stream","text":"Fold 0\n[0.8214285714285714, 0.7575757575757576, 0.4444444444444444, 0.14285714285714285, 0.0, 0.2222222222222222]\nFold 1\n[0.8461538461538461, 0.6071428571428571, 0.375, 0.23076923076923078, 0.08333333333333333, 0.9230769230769231]\nFold 2\n[0.5625, 0.8695652173913043, 0.14285714285714285, 0.4166666666666667, 0.0, 0.5384615384615384]\nFold 3\n[0.8709677419354839, 0.41935483870967744, 0.4, 0.25, 0.14285714285714285, 0.9230769230769231]\nFold 4\n[0.8064516129032258, 0.8181818181818182, 0.14285714285714285, 0.08333333333333333, 0.08333333333333333, 0.2222222222222222]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### We see from the above that each model/fold has better prediction skills for certain ISUP scores than others.\n### Let's: \n### 1) define random sample of data. Will include training data unavoidably. Perform predictions for each fold model\n### 2) see accuracy of simple average of k_fold predictions\n### 3) see accuracy of weighed average of k_fold predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1) defining random rample\ntest_sample_size = sample_size\nsample_test_set = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv').copy()\nsample_test_set= sample_test_set.sample(test_sample_size)\nsample_test_set.to_csv('sample.csv', sep=\",\", index=False)\n","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1) performing predictions\nsample_test_data = load_csv(csv_file='sample.csv', root_dir='../input/prostate-cancer-tiles-4x4x128px-downsampling-4x/train_128x4x4_res1/train_128x4x4_res1')\nsample_test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n    \n\nsample_test_data_preds = []\nfor i in range(num_folds):\n    # Load checkpoint\n    checkpoint_name = \"../input/training-model-with-k-folds/model_fold_\" + str(i) + \".pth\"\n    checkpoint = torch.load(checkpoint_name)\n\n    # Load model parameters\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model._fc.load_state_dict(checkpoint['classifier_state_dict'])\n\n    # Load other model related components\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    fold = checkpoint['fold']\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n    \n    # Load appropriate data (can't use non-test images for testing/predicting)\n    file_path = '../input/training-model-with-k-folds/test_fold_' + str(0) + '.csv'\n    fold_test_set = pd.read_csv(file_path).copy()\n    fold_test_set = fold_test_set.sample(sample_size)\n    \n    fold_sample_name = 'sample_fold_' + str(i) + '.csv'\n    fold_test_set.to_csv(fold_sample_name, sep=\",\", index=False)\n    test_data = load_csv(csv_file=fold_sample_name, root_dir='../input/prostate-cancer-tiles-4x4x128px-downsampling-4x/train_128x4x4_res1/train_128x4x4_res1')\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n    \n    # Run predictions for each fold and hopefully get insights\n    model.eval()\n    \n    with torch.no_grad():\n        test_loss, accuracy, image_id, pred_y, labels, df_test = validate_data_function(model, sample_test_loader, criterion)\n    sample_test_data_preds.append(df_test)\n    print(\"|Fold: {}  |Test Accuracy: {:.2f}%\".format(fold, accuracy))","execution_count":57,"outputs":[{"output_type":"stream","text":"|Fold: 0  |Test Accuracy: 0.38%\n|Fold: 1  |Test Accuracy: 0.48%\n|Fold: 2  |Test Accuracy: 0.53%\n|Fold: 3  |Test Accuracy: 0.43%\n|Fold: 4  |Test Accuracy: 0.49%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(num_folds):\n    fold_preds = pd.DataFrame(sample_test_data_preds[i])\n    name = 'fold_' + str(i) + '_y_pred'\n    sample_test_set[name]= [x for x in fold_preds['y_pred']]","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test_set","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"                               image_id data_provider  isup_grade  \\\n5384   84da53ac6f8828a494a0a8c52a6cd158       radboud           4   \n3554   58d694da01f1b0a9c828857ada4ce80c    karolinska           0   \n146    03ca7f8d8c993d3959daf10ef57f4489    karolinska           1   \n7439   b4543b24750d5bec27fb4918d0a4d543    karolinska           1   \n10549  fe8e6d622955498e6d221940363f57b4    karolinska           0   \n...                                 ...           ...         ...   \n1101   1c36c6b2d051fd1952232efb2613808d       radboud           4   \n8599   cf77075f910326e17c57d890d6bbd6e1    karolinska           3   \n8067   c318254a6de21ceee63f97a015e90d3d    karolinska           1   \n9792   ed9a38a9f1dfa898e536cd91f13d98b1       radboud           3   \n7695   ba90d2787827da36ae89c1512c8d5523       radboud           0   \n\n      gleason_score  fold_0_y_pred  fold_1_y_pred  fold_2_y_pred  \\\n5384            4+4              0              0              0   \n3554            0+0              1              2              1   \n146             3+3              0              5              5   \n7439            3+3              1              1              1   \n10549           0+0              2              1              1   \n...             ...            ...            ...            ...   \n1101            4+4              1              4              0   \n8599            4+3              0              4              1   \n8067            3+3              0              0              0   \n9792            4+3              3              5              3   \n7695       negative              0              0              0   \n\n       fold_3_y_pred  fold_4_y_pred  fold_avg  w_score_int  \n5384               0              0         0            0  \n3554               2              1         1            1  \n146                5              5         4            4  \n7439               1              1         1            1  \n10549              3              1         2            1  \n...              ...            ...       ...          ...  \n1101               0              0         1            0  \n8599               1              0         1            1  \n8067               1              1         0            0  \n9792               3              2         3            4  \n7695               0              0         0            0  \n\n[100 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n      <th>fold_0_y_pred</th>\n      <th>fold_1_y_pred</th>\n      <th>fold_2_y_pred</th>\n      <th>fold_3_y_pred</th>\n      <th>fold_4_y_pred</th>\n      <th>fold_avg</th>\n      <th>w_score_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5384</th>\n      <td>84da53ac6f8828a494a0a8c52a6cd158</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3554</th>\n      <td>58d694da01f1b0a9c828857ada4ce80c</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>03ca7f8d8c993d3959daf10ef57f4489</td>\n      <td>karolinska</td>\n      <td>1</td>\n      <td>3+3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7439</th>\n      <td>b4543b24750d5bec27fb4918d0a4d543</td>\n      <td>karolinska</td>\n      <td>1</td>\n      <td>3+3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10549</th>\n      <td>fe8e6d622955498e6d221940363f57b4</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1101</th>\n      <td>1c36c6b2d051fd1952232efb2613808d</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8599</th>\n      <td>cf77075f910326e17c57d890d6bbd6e1</td>\n      <td>karolinska</td>\n      <td>3</td>\n      <td>4+3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8067</th>\n      <td>c318254a6de21ceee63f97a015e90d3d</td>\n      <td>karolinska</td>\n      <td>1</td>\n      <td>3+3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9792</th>\n      <td>ed9a38a9f1dfa898e536cd91f13d98b1</td>\n      <td>radboud</td>\n      <td>3</td>\n      <td>4+3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7695</th>\n      <td>ba90d2787827da36ae89c1512c8d5523</td>\n      <td>radboud</td>\n      <td>0</td>\n      <td>negative</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows  11 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2) Get simple average\nsample_test_set['fold_avg'] = sample_test_set[['fold_0_y_pred', 'fold_1_y_pred', 'fold_2_y_pred', 'fold_3_y_pred', 'fold_4_y_pred']].mean(axis=1).round(0).astype(int) \n\nequality = sample_test_set[sample_test_set['isup_grade']==sample_test_set['fold_avg']]\naccuracy = len(equality)/len(sample_test_set)\naccuracy","execution_count":70,"outputs":[{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"0.11"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_dict","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"                                            image_id  \\\n0  [7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...   \n1  [7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...   \n2  [7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...   \n3  [7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...   \n4  [7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...   \n\n                                               label  \\\n0  [3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...   \n1  [3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...   \n2  [3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...   \n3  [3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...   \n4  [3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...   \n\n                                              y_pred  \n0  [0, 2, 1, 2, 1, 1, 3, 1, 0, 0, 0, 2, 1, 2, 1, ...  \n1  [5, 3, 4, 5, 0, 2, 1, 1, 0, 0, 0, 5, 4, 5, 1, ...  \n2  [3, 1, 1, 2, 1, 1, 5, 1, 1, 1, 0, 5, 1, 1, 1, ...  \n3  [3, 3, 1, 3, 4, 2, 0, 2, 0, 0, 0, 5, 1, 5, 2, ...  \n4  [4, 1, 1, 1, 0, 1, 4, 0, 0, 0, 0, 3, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>label</th>\n      <th>y_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...</td>\n      <td>[3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...</td>\n      <td>[0, 2, 1, 2, 1, 1, 3, 1, 0, 0, 0, 2, 1, 2, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...</td>\n      <td>[3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...</td>\n      <td>[5, 3, 4, 5, 0, 2, 1, 1, 0, 0, 0, 5, 4, 5, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...</td>\n      <td>[3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...</td>\n      <td>[3, 1, 1, 2, 1, 1, 5, 1, 1, 1, 0, 5, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...</td>\n      <td>[3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...</td>\n      <td>[3, 3, 1, 3, 4, 2, 0, 2, 0, 0, 0, 5, 1, 5, 2, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[7adbbe8f689e5d5c0593855b056f7019, 8f8d20fc6e9...</td>\n      <td>[3, 3, 1, 2, 1, 1, 1, 0, 0, 0, 0, 4, 1, 4, 1, ...</td>\n      <td>[4, 1, 1, 1, 0, 1, 4, 0, 0, 0, 0, 3, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3) Get weighted average\ndef weight_determ(weights_dict, fold, score):\n        return weights_dict[fold][score]\n    \nweight_determ(weights_dic, 4, 3)\n","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"0.08333333333333333"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero = sample_test_set['fold_0_y_pred']\none = sample_test_set['fold_1_y_pred']\ntwo = sample_test_set['fold_2_y_pred']\nthree = sample_test_set['fold_3_y_pred']\nfour = sample_test_set['fold_4_y_pred']\n\nzero_w = [weights_dic[0][int(x)] for x in zero]\none_w = [weights_dic[1][int(x)] for x in one]\ntwo_w = [weights_dic[2][int(x)] for x in two]\nthree_w = [weights_dic[3][int(x)] for x in three]\nfour_w = [weights_dic[4][int(x)] for x in four]\n\ncalc_df = pd.DataFrame()\ncalc_df['zero']= zero\ncalc_df['one']= one\ncalc_df['two']= two\ncalc_df['three']= three\ncalc_df['four']= four\n\ncalc_df['zero_w']= zero_w\ncalc_df['one_w']= one_w\ncalc_df['two_w']= two_w\ncalc_df['three_w']= three_w\ncalc_df['four_w']= four_w\n\n\n'''\nsample_test_set['fold_w_avg'] = [(weight_determ(weights_dict, 0, int(x))*x + weight_determ(weights_dict, 1, int(y))*y \\\n                                 + weight_determ(weights_dict, 2, int(z))*z +weight_determ(weights_dict, 3, int(a))*a \\\n                                 + weight_determ(weights_dict, 4, int(b))*b) \\\n                                 / (weight_determ(weights_dict, 0, int(x)) + weight_determ(weights_dict, 1, int(y)) \\\n                                 + weight_determ(weights_dict, 2, int(z)) + weight_determ(weights_dict, 3, int(a)) \\\n                                 + weight_determ(weights_dict, 4, int(b)))\n                                 for x in zero for y in one for z in two for a in three for b in four]\n'''","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"\"\\nsample_test_set['fold_w_avg'] = [(weight_determ(weights_dict, 0, int(x))*x + weight_determ(weights_dict, 1, int(y))*y                                  + weight_determ(weights_dict, 2, int(z))*z +weight_determ(weights_dict, 3, int(a))*a                                  + weight_determ(weights_dict, 4, int(b))*b)                                  / (weight_determ(weights_dict, 0, int(x)) + weight_determ(weights_dict, 1, int(y))                                  + weight_determ(weights_dict, 2, int(z)) + weight_determ(weights_dict, 3, int(a))                                  + weight_determ(weights_dict, 4, int(b)))\\n                                 for x in zero for y in one for z in two for a in three for b in four]\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"calc_df['numerator'] = calc_df['zero_w']*calc_df['zero'] + calc_df['one_w']*calc_df['one'] + calc_df['two_w']*calc_df['two'] \\\n+ calc_df['three_w']*calc_df['three'] + calc_df['four_w']*calc_df['four']\n\ncalc_df['denominator'] = calc_df['zero_w']+calc_df['one_w']+calc_df['two_w']+calc_df['three_w']+calc_df['four_w']\n\ncalc_df['w_score_float'] = calc_df['numerator']/calc_df['denominator']\ncalc_df['w_score_int'] = [round(x) for x in calc_df['w_score_float']]\nsample_test_set['w_score_int'] = calc_df['w_score_int']","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"equality = sample_test_set[sample_test_set['isup_grade']==sample_test_set['w_score_int']]\naccuracy = len(equality)/len(sample_test_set)\naccuracy","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"0.11"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}